,file_path,api_count,code
0,mcnn/data.py,38,"b'import os\nfrom PIL import Image\nimport numpy as np\nimport tensorflow as tf\nimport tensorlayer as tl\nfrom xml.etree.ElementTree import ElementTree as ET\n\nimg_height = 256\nimg_width = 128\n\n\ndef load_index(is_train):\n    if is_train == True:\n        index_file = ""../TRAIN/indexs.txt""\n    else:\n        index_file = ""../TEST/indexs.txt""\n\n    with open(index_file) as f:\n        indexs = f.readlines()\n\n    indexs = [i.strip() for i in indexs]\n\n    return indexs\n\n\ndef _load_img(idx, is_train):\n    if is_train == True:\n        img_path = ""../TRAIN/IMAGES_TRAIN""\n    else:\n        img_path = ""../TEST/IMAGES_TEST""\n\n    im = Image.open(""{}/{}.jpg"".format(img_path, idx))\n    im = im.resize((img_width, img_height))\n    in_ = np.array(im, dtype=np.uint8)\n\n    "
1,mcnn/model.py,23,"b'import tensorflow as tf\nimport tensorlayer as tl\nfrom tensorlayer.layers import set_keep\n\ndef conv_lrn_pool(input, conv_shape, conv_strides, pool_size, pool_strides, name):\n    with tf.variable_scope(""model"", None):\n        tl.layers.set_name_reuse(None)\n        network = tl.layers.Conv2dLayer(input,\n                                    act=tf.nn.relu,\n                                    shape=conv_shape,\n                                    strides=conv_strides,\n                                    padding=""SAME"",\n                                    W_init=tf.truncated_normal_initializer(stddev=5e-2),\n                                    b_init=tf.constant_initializer(value=0.0),\n                                    name=""conv_"" + name)\n        network.outputs = tf.nn.lrn(network.outputs, 5, bias=1.0,\n                                alpha=0.00005, beta=0.75, name=""norm_"" + name)\n        network = tl.layers.PoolLayer(network, ksize=pool_size,\n                                  strides=pool_strides,\n                                  padding=""SAME"",\n                                  pool=tf.nn.max_pool,\n                                  name=""pool_"" + name)\n        return network\n\n\ndef branch(input, name):\n    with tf.variable_scope(""model"", None):\n        tl.layers.set_name_reuse(None)\n        network = tl.layers.DenseLayer(input, n_units=512,\n                                   act=tf.nn.relu,\n                                   W_init=tf.truncated_normal_initializer(stddev=5e-2),\n                                   b_init=tf.constant_initializer(value=0.0),\n                                   name=""dense1_"" + name)\n        network = tl.layers.DropoutLayer(network, keep=0.5, name=""drop1_"" + name)\n        network = tl.layers.DenseLayer(network, n_units=512,\n                                   act=tf.nn.relu,\n                                   W_init=tf.truncated_normal_initializer(stddev=5e-2),\n                                   b_init=tf.constant_initializer(value=0.0),\n                                   name=""dense2_"" + name)\n        network = tl.layers.DropoutLayer(network, keep=0.5, name=""drop2_"" + name)\n        return network\n\n\ndef single_branch(input, name):\n    with tf.variable_scope(""model"", None):\n        tl.layers.set_name_reuse(None)\n        network = conv_lrn_pool(input, conv_shape=[3, 3, 200, 300],\n                            conv_strides=[1, 1, 1, 1],\n                            pool_size=[1, 5, 5, 1],\n                            pool_strides=[1, 3, 3, 1],name=name)\n\n        network = tl.layers.FlattenLayer(network, name=\'flatten_\'+name)\n        network = branch(network, name)\n \n        return network\n\n\ndef double_branch(input, name, name1, name2):\n    with tf.variable_scope(""model"", None):\n        tl.layers.set_name_reuse(None)\n        network = conv_lrn_pool(input, conv_shape=[3, 3, 200, 300],\n                            conv_strides=[1, 1, 1, 1],\n                            pool_size=[1, 5, 5, 1],\n                            pool_strides=[1, 3, 3, 1], name=name)\n\n        network = tl.layers.FlattenLayer(network, name=\'flatten_\'+name)\n\n        branch1 = branch(network, name1)\n        branch2 = branch(network, name2)\n\n        return branch1, branch2\n\n\ndef score(input, classes, name):\n    with tf.variable_scope(""model"", None):\n        tl.layers.set_name_reuse(None)\n        return  tl.layers.DenseLayer(input, n_units=classes,\n                                      W_init=tf.truncated_normal_initializer(stddev=0.001),\n                                      b_init=tf.constant_initializer(value=0.0),\n                                      name=name+""_score"")\n\n\ndef loss_acc(y, y_):\n     with tf.variable_scope(""model"", None):\n        tl.layers.set_name_reuse(None)\n        cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(y, y_))\n        correct_prediction = tf.equal(tf.cast(tf.argmax(y, 1), tf.int32), y_)\n        acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n        return cost, acc\n\n\ndef inference(x, y_, reuse):\n    with tf.variable_scope(""model"", reuse=reuse):\n        tl.layers.set_name_reuse(reuse)\n\n        network = tl.layers.InputLayer(x, name=""input_layer"")\n        network = conv_lrn_pool(network, conv_shape=[7, 7, 3, 75],\n                                conv_strides=[1, 2, 2, 1],\n                                pool_size=[1, 3, 3, 1],\n                                pool_strides=[1, 2, 2, 1], name=""layer1"")\n\n        network = conv_lrn_pool(network, conv_shape=[5, 5, 75, 200],\n                                conv_strides=[1, 2, 2, 1],\n                                pool_size=[1, 3, 3, 1],\n                                pool_strides=[1, 2, 2, 1], name=""layer2"")\n\n        hair_output, hat_output = double_branch(network, ""head"", ""hair"", ""hat"")\n        hair_score = score(hair_output, 3, ""hair"")\n        hair_y = hair_score.outputs\n\tif y_ != None:\n        \thair_loss, hair_acc = loss_acc(hair_y, y_[""hair""])\n\n        hat_score = score(hat_output, 2, ""hat"")\n        hat_y = hat_score.outputs\n\tif y_ != None:\n        \that_loss, hat_acc = loss_acc(hat_y, y_[""hat""])\n\n        gender_output = single_branch(network, ""gender"")\n        gender_score = score(gender_output, 3, ""gender"")\n        gender_y = gender_score.outputs\n\tif y_ != None:\n        \tgender_loss, gender_acc = loss_acc(gender_y, y_[""gender""])\n\n        top_output = single_branch(network, ""top"")\n        top_score = score(top_output, 6, ""top"")\n        top_y = top_score.outputs\n\tif y_ != None:\n        \ttop_loss, top_acc = loss_acc(top_y, y_[""top""])\n\n        down_output = single_branch(network, ""down"")\n        down_score = score(down_output, 5, ""down"")\n        down_y = down_score.outputs\n\tif y_ != None:\n        \tdown_loss, down_acc = loss_acc(down_y, y_[""down""])\n\n        shoes_output = single_branch(network, ""shoes"")\n        shoes_score = score(shoes_output, 6, ""shoes"")\n        shoes_y = shoes_score.outputs\n\tif y_ != None:\n        \tshoes_loss, shoes_acc = loss_acc(shoes_y, y_[""shoes""])\n\n        bag_output = single_branch(network, ""bag"")\n        bag_score = score(bag_output, 6, ""bag"")\n        bag_y = bag_score.outputs\n\tif y_ != None:\n        \tbag_loss, bag_acc = loss_acc(bag_y, y_[""bag""])\n\n\tif y_!=None:\n\t\tcost = {""all"": hair_loss+hat_loss+gender_loss+top_loss+down_loss+shoes_loss+bag_loss,\n\t\t        ""hair"":hair_loss, ""hat"":hat_loss, ""gender"":gender_loss,\n\t\t        ""top"":top_loss, ""down"":down_loss, ""shoes"":shoes_loss, ""bag"":bag_loss}\n\t\tacc = {""all"":hair_acc+hat_acc+gender_acc+top_acc+down_acc+shoes_acc+bag_acc,\n\t\t        ""hair"":hair_acc, ""hat"":hat_acc, ""gender"":gender_acc,\n\t\t        ""top"":top_acc, ""down"":down_acc, ""shoes"":shoes_acc, ""bag"":bag_acc}\n        net = {""hair"":hair_score, ""hat"":hat_score, ""gender"":gender_score,\n                ""top"":top_score, ""down"":down_score, ""shoes"":shoes_score, ""bag"":bag_score}\n\n\tif y_!=None:\n        \treturn cost, acc, net\n\treturn net\n\n\n'"
2,mcnn/train_test.py,18,"b'import time\nimport tensorflow as tf\nimport tensorlayer as tl\nfrom data import load_index, data_to_tfrecord, read_and_decode\nfrom model import inference\n\nlearning_rate = 0.1\nbatch_size = 100\nepoches = 100\nn_step_epoch = int(20000/100)\nn_step = n_step_epoch*epoches\nprint_freq =1\n\nprint(""Start."")\nwith tf.device(""/gpu:3""):\n    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n\n    "
3,reading_data/example_tfrecords.py,17,"b'import os\nimport tensorflow as tf\nfrom PIL import Image\n\ncwd = os.getcwd()\n\ndef create_record():\n    \'\'\'\n    \xe6\xad\xa4\xe5\xa4\x84\xe6\x88\x91\xe5\x8a\xa0\xe8\xbd\xbd\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe7\x9b\xae\xe5\xbd\x95\xe5\xa6\x82\xe4\xb8\x8b\xef\xbc\x9a\n    0 -- img1.jpg\n         img2.jpg\n         img3.jpg\n         ...\n    1 -- img1.jpg\n         img2.jpg\n         ...\n    2 -- ...\n    ...\n    \'\'\'\n    writer = tf.python_io.TFRecordWriter(""train.tfrecords"")\n    for index, name in enumerate(num_classes):\n        class_path = cwd + name + ""/""\n        for img_name in os.listdir(class_path):\n            img_path = class_path + img_name\n                img = Image.open(img_path)\n                img = img.resize((224, 224))\n            img_raw = img.tobytes() "
4,reading_data/read_data_time_test.py,18,"b'import os\nimport tensorflow as tf\nfrom tensorflow.python import debug as tf_debug\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport time\n\nroot = ""./ADE20K/images/training/""\n\ndef get_filenames(path):\n    filenames = []\n    for root, dirs, files in os.walk(path):\n        for f in files:\n            if "".jpg"" in f:\n                filenames.append(os.path.join(root, f))\n    return filenames\n\ndef convert_to_tfrecord():\n    writer = tf.python_io.TFRecordWriter(""./training.tfrecords"")\n    filenames = get_filenames(root)\n    for name in filenames:\n        img = Image.open(name)\n        if img.mode == ""RGB"":\n            img = img.resize((256, 256), Image.NEAREST)\n            img_raw = img.tobytes()\n            example = tf.train.Example(features=tf.train.Features(feature={\n                      ""img_raw"":tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw]))\n            }))\n            writer.write(example.SerializeToString())\n    writer.close()\n\ndef read_img(filenames, num_epochs, shuffle=True):\n    filename_queue = tf.train.string_input_producer(filenames, num_epochs=num_epochs, shuffle=True)\n\n    reader = tf.WholeFileReader()\n    key, value = reader.read(filename_queue)\n    img = tf.image.decode_jpeg(value, channels=3)\n    img = tf.image.resize_images(img, size=(256, 256), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n    return img\n\ndef read_tfrecord(filenames, num_epochs, shuffle=True):\n    filename_queue = tf.train.string_input_producer([filenames], num_epochs=num_epochs, shuffle=True)\n\n    reader = tf.TFRecordReader()\n    _, serialized_example = reader.read(filename_queue)\n    features = tf.parse_single_example(serialized_example, features={\n               ""img_raw"": tf.FixedLenFeature([], tf.string),\n    })\n    img = tf.decode_raw(features[""img_raw""], tf.uint8)\n    img =  tf.reshape(img, [256, 256, 3])\n\n    return img\n\nif __name__ == \'__main__\':\n    "
